---
title: "Relaxing/Calming aspects of music for humans and dogs"
author: "Jan Hengeveld"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme:
      primary: "#f59842"
      navbar_bg: "#f5b042"
---

<style type="text/css">
  body{
  font-size: 12pt;
}
</style>


```{r, setup}

library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(grid)
library(knitr)
library(gridExtra)
library(heatmaply)
library(ggdendro)
library(recipes)
```

```{r,}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r, selecting data from spotify and combining for analysis}

dogs <- get_playlist_audio_features("", "5hQo2asoxqQrnJFeufycj1")
humans <- get_playlist_audio_features("", "3B0FtfxNiFOo82o8lmJcIp")
dogsscience <- get_playlist_audio_features("", "0km3mDUsP3LYDS1BZfqsY5")
humansscience <- get_playlist_audio_features("", "1t06IDDtn5eYo4Ow7Fwmcb")

combine4lists <-
bind_rows(
humans |> mutate(category = "Humans"),
dogs |> mutate(category = "Dogs"),
dogsscience |> mutate(category = "Dogsscience"),
humansscience |> mutate(category = "Humansscience")
)
```



### Classification and clustering

```{r}
library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |>
    collect_predictions() |>
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |>
    conf_mat_resampled() |>
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |>
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |>
    ungroup() |> filter(Prediction == Truth) |>
    select(class = Prediction, precision, recall)
}
```

```{r}
clusteringdogsscience <-
  get_playlist_audio_features("bnfcollection", "0km3mDUsP3LYDS1BZfqsY5") |>
  add_audio_analysis() |>
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))
```

```{r}
rand_dogs <- clusteringdogsscience[sample(nrow(clusteringdogsscience), size=30),]
```

```{r uvvhjvefjsdjbskjdv}
clusteringdogsscience_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      valence +
      duration + 
      acousticness + 
      tempo,
    data = rand_dogs
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |>
  # step_range(all_predictors()) |>
  prep(rand_dogs |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")
```

```{r}
clusteringdogs_dist <- dist(clusteringdogsscience_juice, method = "euclidean")
```

```{r}


heatmaply(
  clusteringdogsscience_juice,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidian"
)
```

***

I did a random selection of 30 songs from the playlist 4, dogsscience, to look at some clustering features.

Not surprisingly: energy and loudness are clustered together. Then valence comes together with these. Danceability and tempo are added furtheron. 

The clearest outlier, by far, is the song "Violin Partida No 2. (sic, a purely harpsichord based piece of music, called "Violin..."!) On loudness and -to a lesser extend- valence and loudness. When listening to [this song](https://open.spotify.com/track/3ljSpw1GiiHT8vKwRhHoS3?si=6b8cd824e89f4f48) I can easily understand the high scores on these 3 variables. 

More analysis to follow


***


### Computational-Musicology - "It's a dogs life" {data-commentary-width="650"}

This website describes my project for the course Computational Musicology in the third year of doing a Bachelors study Musicology at the University of Amsterdam (with a specialization in Music Cognition). The course deals with the use of computers as a tool for answering musicological questions.

My project has initially aimed to search for music playlists on Spotify with keywords 'relax', 'relaxation' or 'calming'. Not only for humans but also -and specifically- for dogs. There is a large quantity of music (artists, albums, playlists) available on Spotify with those keywords, also for dogs (and cats, jointly our most favorite pets to live with us, human beings).

I attempted to -first broadly- search, then self-assemble and -select, qualify, compare, and (deeply) analyze music (playlists and individual songs) on Spotify, specifically searching for **similarities** and/or **differences** in 'calming/relaxing music' for humans and for dogs.

The interest stems from my scientific curiosity into the emotional and behavioral effects of sounds (specifically **musical** sounds in this project) for humans and animals (dogs here!) alike. Not least because of my love for my own pet dog, Tess, a 3-year-old Toller Retriever (see photo right here where she is alert and active -which is great- but she needs her relax moments very much too!). Her well-being means the world to me and if we can understand the potential calming effects of sounds to dogs a bit better, I hope this can assist in furthering the broad animal's well-being policies and guidelines.

In the next tabs to the right, graphs and texts will provide some insights into the various aspects of music that I dived into for this project. I hope you'll find it interesting to read!

------------------------------------------------------------------------

![](images/IMG-6162.jpg){width="14cm"}

------------------------------------------------------------------------

### Introduction to the analysis of music for this project, selected on Spotify with keywords 'relax(ation)'/ 'calming'; four playlists defined {data-commentary-width="350"}

**For this project I have analysed playlists on Spotify with keywords 'calming' or '(relax)ing' or 'relaxation'. I qualified, selected & grouped them (eventually after looking at some scientific research, see below) fourfold as follows:**

1.  general relaxation playlist for humans ("Humans")
2.  general relaxation playlist for dogs ("Dogs")
3.  specific relaxation playlist for humans, based upon (some) scientific research ("Humansscience")
4.  specific relaxation playlist for dogs, based upon (some) scientific research ("Dogsscience")

All 4 are own-made playlists/groups.

The **overall corpus** is made from songs from many playlists on Spotify that exist for those keywords. It is my working hypothesis that the first two playlists are hardly different and that a high level of anthropomorphism is applicable =\> we assume that what humans define and perceive as relaxing music will be true for dogs also and -hence- playlist 2 is based (assumption!) on similar criteria/elements as for playlist 1.

Multiple research from various disciplines (neurosciences, psychology, biology, animal studies, some in cooperation with musicologists) has been done into calming/relaxing effects of music, both for humans as for dogs. For the first and third group, humans, we know much more given a broader spectrum of feedback: we have language as feedback system whereas with dogs we are limited to observing their behavior and measuring bodily aspects like blood pressure, heartrate or hormone levels (like cortisol, the 'stress hormone').

With music for dogs, research shows that similar musical aspects towards calming apply as for humans (energy, loudness, pitch, instruments) but also differences (variety, genre, 'nature' sounds). On the aspect of **variety** I refer specifically to [Bowman, 2017](https://www.sciencedirect.com/science/article/abs/pii/S0031938416306977) wherein is stated that "..the effect of habituation may be reduced by increasing the variety of auditory enrichment provided." (end of Abstract). In simple words: dogs get habituated (i.e. bored) when there's little variety in music styles/genres and the calming effect of music dilutes.

Groups 3 and 4, defined on **certain** (bear in mind: I limited myself to just a few studies, see below) scientific research, may show (significant) differences with groups 1 and 2 on a variety of musical 'elements'. Also between groups 3 and 4, I wanted to analyze similarities and -especially- search for differences.

All but 1 (nr. 3) playlists are large, i.e. \> 200 songs each. Nr. 3 only contains 10 songs.

('Elements" are aspects of music that Spotify allows for analysis as described [on Spotify](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features%3E)) e.g. loudness, tempo or mode (major or minor)

It might also be that 'true' calming music for dogs is based on musical elements that disqualify for humans as true music (i.e. pitches in sounds at frequency levels unhearable for humans but hearable for dogs. This is not in scope for this project, one reason being is that Spotify doesn't contain (high-pitched) sounds that are non-perceivable for humans but that dogs CAN hear.

My 3d group is based upon this research into the most relaxing (i.e. anxiety reducing) songs for humans: [neuroscience on anxiety reduction](https://www.inc.com/melanie-curtin/neuroscience-says-listening-to-this-one-song-reduces-anxiety-by-up-to-65-percent.html) with [official playlist](https://open.spotify.com/playlist/71mRGOhRHXZRSbQzouuFw7?si=7879ee525f3d4980). I quote from this article "...participants listened to different songs while researchers measured brain activity as well as physiological states that included heart rate, blood pressure, and rate of breathing." The song elected as nr 1 in a top 10 of most relaxing songs is **"Weightless"** by **Marconi Union** (a song which will be deeply analysed in the next tabs). I further quote: "Equally remarkable is the fact the song was actually constructed to do so. The group that created"Weightless", Marconi Union, did so in collaboration with sound therapists. Its carefully arranged harmonies, rhythms, and bass lines help slow a listener's heart rate, reduce blood pressure and lower levels of the stress hormone cortisol." The group I created for this research is an exact copy of this top 10.

I based my fourth group, called on Spotify "Through a Dogs Ear, science-based supposedly" upon the following paper and the available public playlists in Spotify labeled (published by authors of this research). See ["Through a Dogs Ear"](https://icalmpet.com/wp-content/uploads/BioAcoustic-Research-and-Development-Executive-Summary.pdf). Also have a look at [a review of Leeds work](https://www.coldnosecompanions.com/wp-content/uploads/2020/01/Through-a-Dogs-Ear-Review.pdf) The emphasis of this research is very much on a concept called **psycho- and bioacoustics** I quote: "Psychoacoustics is the discipline that studies the perception of sound in humans. This includes how we listen, our psychological responses, and the physiological impact of music and sound on the human nervous system. Bioacoustics is the study of sound in animals. It looks at how animals communicate, as well as the positive and negative effects of sound in their environments." However, the claims by the authors of "Through a Dogs Ear" are refuted in a recent summary article from 2020, ["Musical Dog"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7022433/) regarding the use of music towards dogs behaviour and well-being, stating (in Abstract): "Overall, exposure to classical music appears to have a calming influence on dogs in stressful environments, with no additional benefit observed from any music purposely designed for dogs (specifically"Through a dog's ear")."

(For those really interested: [Animals](https://www.mdpi.com/journal/animals) is a well-known scientific magazine focused entirely on animals.

**My expectations/assumptions about similarities and/or differences between these 4 groups in regards to the most important musical elements were roughly as follows:**

-   on Loudness, Energy and Danceability I expected all 4 groups to score low
-   on Tempo I expected all groups to be largely in the 60-80 BPM range (as research shows that a musical beat that is close to our (and dogs) heartrate is assistful to relaxation)
-   on other elements like e.g. speechiness, instrumentalness or acousticness I didn't formulate specific expectations beforehand (but was rather surprised with some differences between playlists, see next tab)
-   for the playlist 4 (dogs, science-based) I expected the aspect of 'bioacoustics' to be largely represented in the combined Spotify elements tempo, loudness, danceability and energy; it's near-impossible to weigh the importance of each of these aspects although tempo seems to me a crucial element. Also I was curious to delve into timbre aspects of the dogs science-based playlist to see if there are some common characteristics.

------------------------------------------------------------------------

**The playlists used in Spotify:**

Spotify playlist humans:

<https://open.spotify.com/playlist/3B0FtfxNiFOo82o8lmJcIp?si=d6447cd190234b6a>

Spotify playlist dogs:

<https://open.spotify.com/playlist/5hQo2asoxqQrnJFeufycj1?si=565ef05c6ff24ae0>

Spotify playlist humans scientific:

<https://open.spotify.com/playlist/1t06IDDtn5eYo4Ow7Fwmcb?si=5d4a68e5d2334b34>

Spotify playlist dogs scientific: [here](https://open.spotify.com/playlist/0km3mDUsP3LYDS1BZfqsY5?si=2775cd3b8a18422d)

------------------------------------------------------------------------

### A first analysis of some single musical elements across the 4 playlists {data-commentary-width="550"}

```{r}
akoestiek <- combine4lists |>
   ggplot(aes(x = category, y = acousticness)) +
  
  geom_boxplot()

instrumentaliteit <- combine4lists |>
  ggplot(aes(x = instrumentalness)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

valentie <- combine4lists |>
  ggplot(aes(x = category, y = valence)) +
  geom_violin()

modus <- combine4lists |>
  ggplot(aes(x = mode)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

grid.arrange(akoestiek, instrumentaliteit, valentie, modus, ncol = 2)
```

------------------------------------------------------------------------

I started my analysis of the playlists with a comparison on some single elements between the 4 groups. To the left here I present 4 graphs on individual variables in the playlists and I focus on some musical elements for which I had **no** 'hard' or explicit expectations on what the outcomes would be: on acousticness, instrumentalness, valence and mode. Bear in mind that the playlist "humansscience" only contains 10 songs, hence the low bars in the histograms.

First, acousticness: a surprising difference between the 2 dogs playlists and -especially- the playlist humans.

why histogram for mode: mode is a discrete value (0 or 1 and nothing inbetween) and that's why a histogram is the better way of displaying. The adjacent violin plot on valence has relative low values for

Tempo : the higher the happier the music (valence), the slower the music the sadder.

Really intriguing: both dogs playlists score higher on major mode than minor (regular dogs significantly) BUT....this does NOT correlate with a higher valence figures for these playlists. Whereas normally the major mode is associated with positive valence.

I believe that tempo plays the role here of 'party pooper' on the correlation between mode and valence.

------------------------------------------------------------------------

### Combined analysis of 4 key musical elements, observed over the 4 playlists {data-commentary-width="550"}

```{r, 4 categories compared}

combine4lists <-
  humans |>
  mutate(playlist_name = "Relaxation music humans") |>
  bind_rows(dogs |> mutate(playlist_name = "Relaxation music dogs")) |>
  bind_rows(humansscience |> mutate(playlist_name = "Relaxation humans, science-based")) |>
  bind_rows(dogsscience |> mutate(playlist_name = "Relaxation dogs, science-based")) |>
  mutate(
    playlist_name = fct_relevel(playlist_name, "Relaxation music humans", "Relaxation music dogs", "Relaxation humans, science-based", "Relaxation dogs, science-based")
  )

 setup  <-
  combine4lists |>
  ggplot(                          # Set up the plot.
    aes(
      x = tempo,
      y = energy,
      size = danceability,
      colour = loudness,
      label = track.name           # Labels will be interactively visible.
    )
  ) +
  geom_point() +                   # Scatter plot.
  geom_rug(size = 0.1) +           # Add 'fringes' to show data distribution.
  facet_wrap(~playlist_name, scales = "free") +           # Separate charts per country.
  scale_x_continuous(              # Fine-tune the x axis.
    limits = c(0, 200),
    breaks = c(0, 100, 200),        # Use grid-lines for quadrants only.
                # Remove 'minor' grid-lines.
  ) +
  #scale_y_continuous(              # Fine-tune the y axis in the same way.
  #  limits = c(0, 1),
 #   breaks = c(0, 0.50, 1),
    
 # ) +
  scale_colour_viridis_c(          # Use the cividis palette
    option = "E",                  # Qualitative set.
    alpha = 0.8,                   # Include some transparency
    guide = "none"
  ) +
  scale_size_continuous(           # Fine-tune the sizes of each point.
    guide = "none"                 # Remove the legend for size.
  ) +
  theme_light() +                  # Use a simpler theme.
  labs(                            # Make the titles nice.
    x = "Tempo",
    y = "Energy"
  )

ggplotly(setup)
```

------------------------------------------------------------------------

Comparing the 4 playlists on **key musical elements** tempo (x) , energy (y), loudness (color) and danceability (size) as can be seen in the chart left, brings up some interesting and unexpected differences. As mentioned earlier (see Tab "Introduction..."), I expected a lot of similarity across the playlists on these 4 variables (omitting speechiness here as variable). Much to my surprise, there are much bigger differences than I presumed.

Both dogs playlists score significantly lower on energy than the 2 human playlists. Bear in mind when comparing these graphs that the y axis (for energy) has a different scales for each playlist which means that the differences between humans and dogs are even more dramatic!

The same applies for loudness, where the human playlists score high (yellow) and the dogs playlists much lower (blue).

Tempo for humans centers around 120 BPM whereas for dogs it much more in the 60-80 BPM range.

On danceability also a difference can be seen (on average the dogs playlists have many more smaller cells) but not as big as with the other 3 variables.

What mostly struck me is the wide spread of the songs in playlist 3 humans science-based, across these 4 variables. As these 10 songs - supposedly- form a top 10 of most relaxing song for humans (specifically: to relief anxiety and stress e.g. pre-surgery) why do they not score similarly or at least near to the nr 1. (i.e. most relaxing) song on that list: [Weightless by Marconi Union](https://open.spotify.com/track/6kkwzB6hXLIONkEk9JciA6?si=d4a832d2eef54ec5)? I selected this as the 'archetype' song for this playlist.

With playlist nr. 4, there appears at first sight a -seemingly large- difference on energy (y-axis) level BUT the y-axis are differently scaled so on closer look they are comparable on energy level. For this playlist I chose the song [Totally Beached by Joshua Leeds](https://open.spotify.com/track/0SLtSDSjPupBUmrXtUNgPE?si=bb2db41ce65d445d) as 'archetype' song for this playlist. Partly I chose this because the song has a reggae style 'vibe' to it and this [research](http://eprints.gla.ac.uk/135846/) has identified reggae as a preferred genre by dogs (from a relaxation perspective).

------------------------------------------------------------------------

### Analysis of 2 **'archetype'** songs in terms of chroma features (providing pitch class insights) as can be seen in chromagrams {data-commentary-width="450"}

```{r, selection of several songs for bla chroma analysis}

chromadog <- get_tidy_audio_analysis("0SLtSDSjPupBUmrXtUNgPE") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

chromahuman <- get_tidy_audio_analysis("6kkwzB6hXLIONkEk9JciA6") |>
   select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
```

```{r, chroma bla for humans and dogs libeuclidian}
chromahumanweightless <- chromahuman |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Weightless (Marconi Union)") +
  theme_minimal() +
  scale_fill_viridis_c()

chromadogstotallybeached <- chromadog |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Totally beached (Joshua Leeds)") +
  theme_minimal() +
  scale_fill_viridis_c()
grid.arrange(chromahumanweightless, chromadogstotallybeached, ncol = 1)
```

------------------------------------------------------------------------

**Following earlier analysis I proceeded with a few selected songs from the 2 science-based playlists to deeper analyse other aspects as provided by chromagrams**

This tab explains the pitch-classes structure of the song "Weightless" from playlist 3, humans science as well from the song "Totally Beached", an archetypical song in the playlist 4, dogs science-based.

**WEIGHTLESS**

I selected the song "Weightless" by Marconi Union from group 3 (humans, science-based) upon [this research](https://www.britishacademyofsoundtherapy.com/wp-content/uploads/2019/10/Mindlab-Report-Weightless-Radox-Spa.pdf) into relaxing capabilities of music to lower anxiety in humans (e.g. pre-surgery). This study concluded upon a top 10 list of most relaxing songs, with Weightless as nr 1.

Weightless is -intendedly- not a very energetic or (pitch/chords/beats/timbre) changing song, quite the opposite. When listening to it, I can hear the change to emphasis on D and A happening after exactly 89 seconds. Some, but very little, melodic aspects then come into play. Reason for this is, as explained by the researchers in their study, that -when trying to have humans relax to music- they want to minimize the brain activity related to predicting where the melody is developing to.

(possibly: more explanation to follow)

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/6kkwzB6hXLIONkEk9JciA6?utm_source=generator" width="100%" height="85" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1">

allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"\>

</iframe>

**TOTALLY BEACHED**

I selected the song "Totally beached" from the fourth group (dogs, science-based) for a further analysis because it has a strong reggae 'vibe' to it and [certain research](https://www.scottishspca.org/news/reggae-gets-paw-of-approval) on the effect of music on calming dogs found that reggae music (together with soft rock and classic) is a genre preferred by dogs.

Totally Beached is a relative short song, where in the chromagram I believe to see a clear reggae-style appearance of offbeat chord elements. The song follows a classic reggae chord development between I and IV (in this case G minor and C minor). What surprises me in the chrogram is a relative small prominence of Eb, the terts in C minor. The last 10 seconds are a fading-out stall of the applied instruments, hanging on to a single C-dominated finale.

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/0SLtSDSjPupBUmrXtUNgPE?utm_source=generator" allowfullscreen width="100%" height="85" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy">

</iframe>

------------------------------------------------------------------------

### Some timbre analysis with the help of cepstrograms {data-commentary-width="550"}

```{r, cepstrogram for Weightless Union}

singlehumanscience <-
  get_tidy_audio_analysis("6kkwzB6hXLIONkEk9JciA6") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r, cepstrograms on Totally Beached  first attempts this one for dogs}

singledogsscience <-
  get_tidy_audio_analysis("0SLtSDSjPupBUmrXtUNgPE") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r, cepstrogram on weightless and totally beached combined}
cepstrh <- singlehumanscience|>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", title = "Weightless (Marconi Union)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

cepstrod <- singledogsscience|>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", title = "Totally beached (Joshua Leeds)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
grid.arrange(cepstrh, cepstrod, ncol = 1)
```

------------------------------------------------------------------------

On the left here are 2 cepstrograms, aimed at providing insights into the different timbre aspects of pieces of music.

The cepstrogram on **'Weightless'**, the song elected as most relaxing for humans, shows an enormous amount of c02 timbre elements, meaning a high level of brightness 'at the expense' of other timbre aspects. The first 16 seconds/beats of the song a spread (in green) between C2 and C03 occurs and this relates to the fade-in of the synths elements that reach peak from that moment and -thus- further concentrates in C02. 4.52 minutes into the song another high-pitched element is introduced and from that moment on some more "C02-interrupting" musical elements (mostly high-pitched sounds) are put into the mix of the audio. This can be in the occasional interruption of bright yellow in C02 after 500 seconds in conjunction with green in other timbre aspects.

For the second cepstrogram: first indications make me think that flatness is indeed high in **'Totally Beached'**. Also a relative high level of c04 which relates to the relative sharp 'attack' style of the strumming guitar with reggae. Between seconds 85 and 95 bass guitar and percussion are gone (less C03), then bass guitar comes back (more C02) and then percussion also comes back from second 116 and everything is back to 'normal'. The 2 dark yellow marks for Co3 at 130 seconds and 143 seconds relate to a short cymbal sound at these moments.

Both songs, especially Weightless, score relatively low on C01 (which correlates to loudness) in these cepstrograms and this is in line with the individual loudness variable measurements by the Spotify API (-19.974 for Weightless and -18.861 for Totally Beached).

------------------------------------------------------------------------

### Self-Similarity Matrices

```{r for SSM dogsscience, echo=FALSE, message=FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
singledogscience <-
  get_tidy_audio_analysis("0SLtSDSjPupBUmrXtUNgPE") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  singledogsscience |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  singledogscience |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

```{r for SSM humans outlier dance, echo=FALSE, message=FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
outlierdanceabilityhumans <-
  get_tidy_audio_analysis("2IawV9XXCRxf27TjmrbIZs") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  outlierdanceabilityhumans |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  outlierdanceabilityhumans |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", title = "Disturbia - Lenji", y = "")
```

```{r for SSM humans We can Fly, echo=FALSE, message=FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
wecanfly <-
  get_tidy_audio_analysis("0ziUt5zRNQLNmb9LTV7CoY") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  wecanfly |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  wecanfly |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", title = "We Can Fly - Rue du Soleil", y = "")
```

------------------------------------------------------------------------

Explanation to follow; for Weightless: the song is intendedly designed to lower the BPM

------------------------------------------------------------------------

### Homework for week 10, keys analysis

Homework week 10 continued (part 3): chordogram on keys {data-commentary-width="500"}

```{r, strawberryswing continued}
strawberryswing <- get_tidy_audio_analysis("2dphvmoLEXdk8hOYxmHlI3") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r, strawberry swing pitch outcomes}
strawberryswing |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

Homework week 10 continued (Chordograms) {data-commentary-width="500"}

```{r, echo = FALSE}
strawberryswing <- get_tidy_audio_analysis("2dphvmoLEXdk8hOYxmHlI3") 
strawberryswing|>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  ) |> 
  compmus_match_pitch_template(chord_templates, "euclidean", "manhattan") |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

------------------------------------------------------------------------

As most songs from all 4 playlists are -intendedly- not very 'exciting' in terms of a lot of musical elements (and their possible changes during a song) like tempo, energy, instrumentalness, etc. I decided to pick an outlier from playlist 3 (humansscience) which scores highest on tempo and relatively high on energy: Strawberry Swing by Coldplay, to see what happens chords-wise. A chordagram is presented here.

The song is in Ab (as tonica I) with mostly changes to IV (Db) and V (Eb). This is a rather 'normal' chords progression. The black spot around 95 seconds in Db appears to me the emphasis/power on Db (as 'tension' dominant to Ab) just before 'releasing' to tonica Ab ('home'/stability). The same 'returned home' energy on Ab can been seen in the last 80 seconds of the song. As G# enharmonically is the same as Ab, it is no surprise that there's relative a lot of energy in there too. There's also a prominance to be seen in seventh chords, a usual patterns in chordagrams as explained by our lector: 'leakage' of energy in the 7th 'bin' (close to the 1st tonica) plays a role here sometimes).

------------------------------------------------------------------------

Homework week 10 continued (part 3): timbre comparison between 2 playlists (humans science and dogs science) {data-commentary-width="500"}

```{r, week 10}

humansscience <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "1t06IDDtn5eYo4Ow7Fwmcb"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
dogsscience <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0km3mDUsP3LYDS1BZfqsY5"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
combine2lists <-
  humansscience |>
  mutate(genre = "Humans science") |>
  bind_rows(dogsscience |> mutate(genre = "Dogs Science"))

combine2lists |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(genre, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre")
```

Homework week 10 continued (part 4): timbre comparison between 2 playlists (dogs and dogs science) {data-commentary-width="500"}

```{r, week 10 extra}

dogs <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "5hQo2asoxqQrnJFeufycj1"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
dogsscience <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0km3mDUsP3LYDS1BZfqsY5"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
combine3lists <-
  dogs |>
  mutate(genre = "Dogs") |>
  bind_rows(dogsscience |> mutate(genre = "Dogs Science"))

combine3lists |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(genre, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre")
```

Homework week 10 continued (part 4): loudness comparison between 2 playlists (dogs and dogs science) {data-commentary-width="500"}

```{r, week 10 extra bla}
combine3lists |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

------------------------------------------------------------------------

KEY ANALYSIS

A remarkable (in my opinion) similarity on keys between the groups, the mean in 3 out of 4 groups on key 5, which is F. Only "humansscience" has F# as mean. I find it very remarkable that the key of C (nr. 1), one would expect an often used key, is completely missing in these boxplots. Further to be analysed.

Analysis on chordograms to follow HERE:

As expected, an emphasis on I, IV and V prominence for a song in Ab. Interesting:a lot of dark blue in C# (enharmonically the same as Db). With knowledge of Western chords and their relationships (tonica, subdominant, dominant and others) I expected that the software would 'know' - in the context of this piece of music; circle of fifths!- that Db strongly 'belongs' to Ab and C# not really.

ON CEPSTOGRAMS:

At first sight, no c02 or c03 scores for the humans science groups, that's...remarkable. A handicap of this comparison is that the playlist human science only contains 10 songs. But still, the absence of c02 and c03 is remarkable. In the next tab I will analyse two larger groups, dogs and dogs science.

No major differences are to be seen here between these 2 groups in terms of Timbres except perhaps that categories c06-c10 produces higher scores for Dogs Science.

LOUDNESS COMPARISON: well, at least produced a graph....now for some analysis...:)

------------------------------------------------------------------------

### Concluding remarks {data-commentary-width="700"}

![](images/dogearphone.jpg){width="14cm"}

------------------------------------------------------------------------

DRAFT, bulletpoint like remarks:

-   referring to Pien Zwart's BA afstudeeropdracht (?)

-   dogs playlist more strictly based on criteria for 'true' relaxation (e.g. tempo around 60-80; low energy); the definition for humans relaxation seems, even for the science-based list, more loosely formulated. The relaxation for dogs musical elements cater for the **'real'** form of relaxtion that I searched for (i.e. getting the listener into a state of calm, near-sleep)

-   My construction of the playlists has been based on diverse definitions/criteria regarding the words 'relax(ation)' and/or 'calming'

-   I don't see the aspect of variation in the playlist dogs, science-based whereas this is mentioned in research as an important aspect for the desired effect (calming of dogs)

-   the Spotify API doesn't fully work flawlessly, some musical elements are clearly wrongly analysed and put incorrectly in a data figure. Which means: listen often to the songs!

-   also statements/claims in literature need to be critically assessed and evaluated. Most

-   the playlist humans science is based on a scientifically selected set of 10 most relaxing songs (with the aim of anxiety relief, e.g. pre-surgery). Yet, I find this list in terms of musical aspects like e.g. tempo, energy and speechiness not very well suited for true relaxation; I believe the definition of 'relaxation' for this group, as well as for the general playlist humans is less strict than the definition for the 2 playlists for dogs. The latter 2 are more strictly designed to calm (in terms of heartrate, blood pressure, etc.)

-   the bioacoustic aspects that research (partly leading to my 4th group dogs scientific) into calming effects of sounds to dogs have not been analysed. Spotify doesn't provide Nor does Spotify generate music above (but IN for dogs) the hearing frequency spectrum for humans

-   the aspect of variations in music for dogs, to counter boredom, as described in [this research] as an important factor, I define as a widely scattered set of outcomes of musical variables (e.g. ....) and this isn't the case for the 2 playlists for dogs. The aspects of prediction (based upon expectations) for music, meaning repetition of certain styles, genres etc. I don't think applies to dogs (their brains aren;t that developed)

------------------------------------------------------------------------
