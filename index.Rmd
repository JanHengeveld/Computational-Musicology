---
title: "Relaxing/Calming aspects of music for humans and dogs"
author: "Jan Hengeveld"
date: "2023-03-04"
output:
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
---

```{r, setup}

library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
```

```{r, selecting data from spotify and combining for analysis}

dogs <- get_playlist_audio_features("", "5hQo2asoxqQrnJFeufycj1")
humans <- get_playlist_audio_features("", "3B0FtfxNiFOo82o8lmJcIp")
dogsscience <- get_playlist_audio_features("", "0km3mDUsP3LYDS1BZfqsY5")
humansscience <- get_playlist_audio_features("", "1t06IDDtn5eYo4Ow7Fwmcb")

combine4lists <-
bind_rows(
humans |> mutate(category = "Humans"),
dogs |> mutate(category = "Dogs"),
dogsscience |> mutate(category = "Dogsscience"),
humansscience |> mutate(category = "Humansscience")
)
```

### Computational-Musicology {data-commentary-width="600"}

This website describes my project for the course Computational Musicology in the third year of doing a Bachelors study Musicology at the University of Amsterdam (with a specialization in Music Cognition). The course deals with the use of computers as a tool for answering musicological questions.

My project has initially aimed to search for music playlists on Spotify with keywords 'relax', 'relaxation' or 'calming'. Not only for humans but also -specifically- for dogs. There is a large quantity of music (artists, albums, playlists) available on Spotify with those keywords, also for dogs (and cats, jointly our most favorite pets to live with us, human beings).

I attempt (present tense at this stage...) to -first broadly- search, then self-assemble and -select, compare, and (deeply) analyze music (playlists and individual songs) on Spotify, specifically searching for **similarities** and/or **differences** in 'calming/relaxing music' for humans and for dogs.

The interest stems from my scientific curiosity into the emotional and behavioral effects of sounds (specifically **musical** sounds in this project) for humans and animals (dogs here!) alike. Not least because of my love for my own pet dog, Tess, a 3-year-old Toller Retriever. Her well-being means the world to me and if we can understand the potential calming effects of sounds to dogs a bit better I hope this can assist in furthering the broad animal's well-being policies and guidelines.

------------------------------------------------------------------------

![](images/IMG-6162.jpg){width="14cm"}

### Introduction to analysis of music, made and selected on Spotify for 'relax(ation)'/'calming' {data-commentary-width="500"}

**For this project I have analysed playlists on Spotify which are named either 'calming' or 'relaxing' or 'relaxation' and qualified, selected & grouped them (eventually after some further research) fourfold as follows:**

1.  general relaxation playlist for humans
2.  general relaxation playlist for dogs
3.  specific relaxation playlist for humans, based upon scientific research
4.  specific relaxation playlist for dogs, based upon (some) scientific research

(all 4 are own-made playlists)

The overall corpus is made from songs on many playlists that exist for those groups. It is my working hypothesis that the first two groups are hardly different and that a high level of anthropomorphism is applicable =\> we assume that what humans define and perceive as relaxing music will be true for dogs also and hence group 2 is based on similar criteria/elements as for group 1.

Research has been done into calming/relaxing effects of music, both for humans as for dogs. For the first group, humans, we know much more given a higher quality level of feedback. For dogs, research shows that similar aspects apply as for humans (energy, loudness, pitch, instruments) but also differences (variety, genre, 'nature'sounds).

Group 3 and 4, defined on certain scientific research, may show significant differences with groups 1 and 2 on a variety of musical 'elements'. Also between groups 3 and 4, I wanted to analyze similarities and -especially- search for differences. This was a key research goal for this project.

('Elements" are the ones that Spotify allows for analysis as described on: <https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features>)

It might also be that 'true' calming music for dogs is based on musical elements that disqualify for humans as true music (i.e. pitches in sounds at frequency levels unhearable for humans but hearable for dogs. This is not in scope for this project, one reason being is that Spotify doesn't contain (high-pitched) sounds that are non-perceivable for humans but that dogs CAN hear.

My 3d group is based upon the following research into the most relaxing (i.e. anxiety reducing) songs for humans: <https://www.inc.com/melanie-curtin/neuroscience-says-listening-to-this-one-song-reduces-anxiety-by-up-to-65-percent.html>, resulting in a 3d group of 10 songs

This is the link: <https://open.spotify.com/playlist/71mRGOhRHXZRSbQzouuFw7?si=7879ee525f3d4980>, the group I created for this research is an exact copy hereof.

I based my fourth group, called on Spotify "Through a Dogs Ear, science-based supposedly" upon the following paper and the available public playlists in Spotify labeled"Through a Dogs Ear" (published by authors of this research). See <https://icalmpet.com/wp-content/uploads/BioAcoustic-Research-and-Development-Executive-Summary.pdf>

My expectations about similarities and/or differences between these 4 groups in regards to the most important musical elements were roughly as follows:

-   on Loudness, Energy, Speechiness and Danceability I expected all 4 groups to score low
-   on Tempo I expected all groups to be largely in the 60-80 BPM range (as research shows that a musical beat that is close to our heartrate is assistfull to relaxation)
-   on other elements I didn't formulate specific expectations beforehand

------------------------------------------------------------------------

**The playlists used in Spotify:** 

Spotify playlist humans:

<https://open.spotify.com/playlist/3B0FtfxNiFOo82o8lmJcIp?si=d6447cd190234b6a>


Spotify playlist dogs:

<https://open.spotify.com/playlist/5hQo2asoxqQrnJFeufycj1?si=565ef05c6ff24ae0>

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/3B0FtfxNiFOo82o8lmJcIp?utm_source=generator" width="70%" height="352" frameBorder="0" allowfullscreen allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>


Spotify playlist humans scientific:

<https://open.spotify.com/playlist/1t06IDDtn5eYo4Ow7Fwmcb?si=5d4a68e5d2334b34>


Spotify playlist dogs scientific:

<https://open.spotify.com/playlist/0km3mDUsP3LYDS1BZfqsY5?si=2775cd3b8a18422d>


------------------------------------------------------------------------

### A global analysis of 4 relaxation playlists: humans, dogs, 'humansscience' and 'dogsscience'

**I started the analysis with a comparison on single elements between the 4 groups**

(N.B. at the moment this is still a garbage tab which requires clean-up)

<https://open.spotify.com/playlist/48fYbZUMrk5mJwhfj3xAi4?si=e4adb9f034634348>

------------------------------------------------------------------------

```{r, 1 single variable compared}
combine4lists |>
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
combine4lists |>
  ggplot(aes(x = category, y = energy)) +
  geom_boxplot()
combine4lists |>
  ggplot(aes(x = category, y = energy)) +
  geom_violin()
```

```{r, 1 single variable compared; tempo}
combine4lists |>
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
combine4lists |>
  ggplot(aes(x = category, y = tempo)) +
  geom_boxplot()
combine4lists |>
  ggplot(aes(x = category, y = tempo)) +
  geom_violin()
```

```{r, 1 single variable compared; speechiness}
combine4lists |>
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
combine4lists |>
  ggplot(aes(x = category, y = speechiness)) +
  geom_boxplot()
combine4lists |>
  ggplot(aes(x = category, y = speechiness)) +
  geom_violin()
```

```{r, 1 single variable compared; valence}
combine4lists |>
  ggplot(aes(x = valence)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
combine4lists |>
  ggplot(aes(x = category, y = valence)) +
  geom_boxplot()
combine4lists |>
  ggplot(aes(x = category, y = valence)) +
  geom_violin()
```

```{r, 1 single variable compared; mode}
combine4lists |>
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
combine4lists |>
  ggplot(aes(x = category, y = mode)) +
  geom_boxplot()
combine4lists |>
  ggplot(aes(x = category, y = mode)) +
  geom_violin()
```

------------------------------------------------------------------------

```{r, scatterplots}

dogs |> ggplot(aes(x = tempo, y = energy)) + geom_point() + geom_smooth()
## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'


```

```{r, code from ashley}
dogs |>                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) |>
  ggplot(                     # Set up the plot.
    aes(
      x = loudness,
      y = energy,
      size = valence,
      colour = mode
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(linewidth = 0.1) + # Add 'fringes' to show data distribution.
  geom_text(                  # Add text labels from above.
    aes(
      x = valence,
      y = energy,
      label = label
    ),
    data = 
      tibble(
        label = c("Outlier", "ENERGY"),
        category = c("Edisons", "Grammys"),
        valence = c(0.090, 0.123),
        energy = c(0.101, 0.967)
      ),
    colour = "black",         # Override colour (not mode here).
    size = 3,                 # Override size (not loudness here).
    hjust = "left",           # Align left side of label with the point.
    vjust = "bottom",         # Align bottom of label with the point.
    nudge_x = -0.05,          # Nudge the label slightly left.
    nudge_y = 0.02            # Nudge the label slightly up.
  ) +
  facet_wrap(~ category) +    # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "loudness",
    y = "Energy",
    colour = "Mode"
  )

```

```{r, code from ashley2}
humans |>                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) |>
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = loudness,
      colour = mode
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(linewidth = 0.1) + # Add 'fringes' to show data distribution.
  geom_text(                  # Add text labels from above.
    aes(
      x = valence,
      y = energy,
      label = label
    ),
    data = 
      tibble(
        label = c("OUtlier", "ENERGY"),
        category = c("Edisons", "Grammys"),
        valence = c(0.090, 0.123),
        energy = c(0.101, 0.967)
      ),
    colour = "black",         # Override colour (not mode here).
    size = 3,                 # Override size (not loudness here).
    hjust = "left",           # Align left side of label with the point.
    vjust = "bottom",         # Align bottom of label with the point.
    nudge_x = -0.05,          # Nudge the label slightly left.
    nudge_y = 0.02            # Nudge the label slightly up.
  ) +
  facet_wrap(~ category) +    # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "loudness",
    y = "Energy",
    colour = "Mode"
  )

```

### Further chroma analysis into a few selected songs

#### I selected the song "Weightless" by Marconi Union from group 3 (humans, science-based) upon the following research:

<https://www.britishacademyofsoundtherapy.com/wp-content/uploads/2019/10/Mindlab-Report-Weightless-Radox-Spa.pdf>\>. This study concluded upon a top 10 list of most relaxing song, with Weightless as nr 1.

#### I selected the song "Totally beached" from the fourth group (dogs, science-based) for a further analysis because it has a strong Reggae 'vibe' to it and other research on the effect of music on calming dogs found that Reggae music was preferred by dogs (reference to article)


```{r, chroma analysis for dogs}

chromadog <- get_tidy_audio_analysis("0SLtSDSjPupBUmrXtUNgPE") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

chromahuman <- get_tidy_audio_analysis("6kkwzB6hXLIONkEk9JciA6") |>
   select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

chromadog |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
```{r, chroma for humans}
chromahuman |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```


```{r eval=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
maria <-
  get_tidy_audio_analysis("2MZSXhq4XDJWu6coGoXX1V") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  maria |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  maria |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```


### Homework for Week 9; chromagrams and cepstograms




### Concluding remarks
